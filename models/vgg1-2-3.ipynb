{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8564514,"sourceType":"datasetVersion","datasetId":5120109},{"sourceId":8598079,"sourceType":"datasetVersion","datasetId":5143901}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T13:11:41.737504Z","iopub.execute_input":"2024-06-04T13:11:41.738215Z","iopub.status.idle":"2024-06-04T13:11:42.161508Z","shell.execute_reply.started":"2024-06-04T13:11:41.738180Z","shell.execute_reply":"2024-06-04T13:11:42.160527Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset-users/users (2).json\n/kaggle/input/user-vgg-features/user_features.json\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:42.163569Z","iopub.execute_input":"2024-06-04T13:11:42.164132Z","iopub.status.idle":"2024-06-04T13:11:54.231301Z","shell.execute_reply.started":"2024-06-04T13:11:42.164094Z","shell.execute_reply":"2024-06-04T13:11:54.230393Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-04 13:11:44.291637: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-04 13:11:44.291748: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-04 13:11:44.390709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load JSON data\nwith open('/kaggle/input/user-vgg-features/user_features.json', 'r') as file:\n    features = json.load(file)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:54.232527Z","iopub.execute_input":"2024-06-04T13:11:54.233114Z","iopub.status.idle":"2024-06-04T13:11:54.609350Z","shell.execute_reply.started":"2024-06-04T13:11:54.233085Z","shell.execute_reply":"2024-06-04T13:11:54.608339Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/dataset-users/users (2).json','r') as file: \n    users = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:54.611644Z","iopub.execute_input":"2024-06-04T13:11:54.611933Z","iopub.status.idle":"2024-06-04T13:11:56.811808Z","shell.execute_reply.started":"2024-06-04T13:11:54.611909Z","shell.execute_reply":"2024-06-04T13:11:56.810889Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Prepare input X and target y\nX = []\ny = []\n\nfor user in users:\n    user_id = user['user_id']\n    if user_id in features:\n        # Add the feature vector to X\n        X.append(features[user_id])\n\n        # Extract sub-interests\n        interests = user.get('interests', {})\n        sub_interests = [sub_interest for category in interests.values() for sub_interest in category]\n        y.append(sub_interests)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.815678Z","iopub.execute_input":"2024-06-04T13:11:56.816468Z","iopub.status.idle":"2024-06-04T13:11:56.825776Z","shell.execute_reply.started":"2024-06-04T13:11:56.816438Z","shell.execute_reply":"2024-06-04T13:11:56.824633Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Convert X and y to numpy arrays\nX = np.array(X)\n\n# Binarize the labels for multi-label classification\nmlb = MultiLabelBinarizer()\ny = mlb.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.827244Z","iopub.execute_input":"2024-06-04T13:11:56.827554Z","iopub.status.idle":"2024-06-04T13:11:56.879331Z","shell.execute_reply.started":"2024-06-04T13:11:56.827528Z","shell.execute_reply":"2024-06-04T13:11:56.878405Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\n\n# Calculate the number of instances for each class in the target labels\nclass_instances = defaultdict(int)\nfor labels in y:\n    for i, label in enumerate(labels):\n        if label == 1:\n            class_instances[i] += 1","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.880519Z","iopub.execute_input":"2024-06-04T13:11:56.880866Z","iopub.status.idle":"2024-06-04T13:11:56.906649Z","shell.execute_reply.started":"2024-06-04T13:11:56.880833Z","shell.execute_reply":"2024-06-04T13:11:56.905742Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"threshold = 70\n\n# Identify minor classes with fewer instances\nminor_classes = [class_idx for class_idx, count in class_instances.items() if count < threshold]\n\n# Define augmentation parameters\nnoise_std = 0.1  # Standard deviation of Gaussian noise\nmin_scale = 0.8  # Minimum scaling factor\nmax_scale = 1.2  # Maximum scaling factor","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.907747Z","iopub.execute_input":"2024-06-04T13:11:56.908048Z","iopub.status.idle":"2024-06-04T13:11:56.912978Z","shell.execute_reply.started":"2024-06-04T13:11:56.908023Z","shell.execute_reply":"2024-06-04T13:11:56.912028Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def add_gaussian_noise(feature_vector):\n    noise = np.random.normal(loc=0, scale=noise_std, size=feature_vector.shape)\n    return feature_vector + noise\n\n# Function to perform random scaling on a feature vector\ndef random_scaling(feature_vector):\n    scale_factor = np.random.uniform(min_scale, max_scale)\n    scaled_vector = feature_vector * scale_factor\n    return scaled_vector\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.914261Z","iopub.execute_input":"2024-06-04T13:11:56.914759Z","iopub.status.idle":"2024-06-04T13:11:56.921215Z","shell.execute_reply.started":"2024-06-04T13:11:56.914726Z","shell.execute_reply":"2024-06-04T13:11:56.920274Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Define a function for data augmentation\ndef augment_data(X):\n    # Add Gaussian noise\n    X_noise = X + np.random.normal(0, 0.1, size=X.shape)\n    \n    # Random scaling\n    scaling_factor = np.random.uniform(0.9, 1.1, size=(X.shape[0], 1))\n    X_scaled = X * scaling_factor\n    \n    # Concatenate original data with augmented data\n    X_augmented = np.concatenate([X, X_noise, X_scaled], axis=0)\n    \n    return X_augmented","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.924170Z","iopub.execute_input":"2024-06-04T13:11:56.924551Z","iopub.status.idle":"2024-06-04T13:11:56.930311Z","shell.execute_reply.started":"2024-06-04T13:11:56.924527Z","shell.execute_reply":"2024-06-04T13:11:56.929442Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Perform data augmentation for minor classes in the training data\naugmented_X = list(X)  # Start with original data\naugmented_y = list(y)\n\nfor i, x in enumerate(X):\n    for j, y_label in enumerate(y[i]):\n        if j in minor_classes and y_label == 1:\n            # Add Gaussian noise\n            augmented_feature_vector_1 = add_gaussian_noise(x)\n            augmented_X.append(augmented_feature_vector_1)  # Append to the list\n            augmented_y.append(y[i])\n\n            # Random scaling\n            augmented_feature_vector_2 = random_scaling(x)\n            augmented_X.append(augmented_feature_vector_2)  # Append to the list\n            augmented_y.append(y[i])\n\n# Convert augmented data to numpy arrays\naugmented_X = np.array(augmented_X)\naugmented_y = np.array(augmented_y)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:56.931518Z","iopub.execute_input":"2024-06-04T13:11:56.931802Z","iopub.status.idle":"2024-06-04T13:11:57.025924Z","shell.execute_reply.started":"2024-06-04T13:11:56.931780Z","shell.execute_reply":"2024-06-04T13:11:57.025184Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"augmented_X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:57.027286Z","iopub.execute_input":"2024-06-04T13:11:57.027609Z","iopub.status.idle":"2024-06-04T13:11:57.034866Z","shell.execute_reply.started":"2024-06-04T13:11:57.027583Z","shell.execute_reply":"2024-06-04T13:11:57.033977Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(2992, 1, 512)"},"metadata":{}}]},{"cell_type":"code","source":"augmented_X = np.array(augmented_X).reshape(len(augmented_X), -1)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:57.035952Z","iopub.execute_input":"2024-06-04T13:11:57.036321Z","iopub.status.idle":"2024-06-04T13:11:57.047222Z","shell.execute_reply.started":"2024-06-04T13:11:57.036295Z","shell.execute_reply":"2024-06-04T13:11:57.046169Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"augmented_X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:57.048522Z","iopub.execute_input":"2024-06-04T13:11:57.049118Z","iopub.status.idle":"2024-06-04T13:11:57.055278Z","shell.execute_reply.started":"2024-06-04T13:11:57.049085Z","shell.execute_reply":"2024-06-04T13:11:57.054142Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(2992, 512)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nfrom sklearn.metrics import f1_score\n\nclass F1ScoreCallback(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        y_pred = self.model.predict(X_test)\n        y_pred = (y_pred > 0.5).astype(int)\n        f1 = f1_score(y_test, y_pred, average='micro')\n        print(f' - val_f1_score: {f1:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:57.056727Z","iopub.execute_input":"2024-06-04T13:11:57.057180Z","iopub.status.idle":"2024-06-04T13:11:57.065285Z","shell.execute_reply.started":"2024-06-04T13:11:57.057147Z","shell.execute_reply":"2024-06-04T13:11:57.064237Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(augmented_X, augmented_y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:11:57.066484Z","iopub.execute_input":"2024-06-04T13:11:57.066889Z","iopub.status.idle":"2024-06-04T13:11:57.077526Z","shell.execute_reply.started":"2024-06-04T13:11:57.066856Z","shell.execute_reply":"2024-06-04T13:11:57.076435Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define the neural network model\nvgg2 = Sequential([\n    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.5),\n    Dense(y.shape[1], activation='sigmoid') \n])\n# Compile the model\nvgg2.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:18:47.493694Z","iopub.execute_input":"2024-06-04T13:18:47.494492Z","iopub.status.idle":"2024-06-04T13:18:48.336211Z","shell.execute_reply.started":"2024-06-04T13:18:47.494460Z","shell.execute_reply":"2024-06-04T13:18:48.335375Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg2.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,validation_data=(X_test, y_test), callbacks=[F1ScoreCallback()])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:18:48.337727Z","iopub.execute_input":"2024-06-04T13:18:48.338019Z","iopub.status.idle":"2024-06-04T13:19:10.736843Z","shell.execute_reply.started":"2024-06-04T13:18:48.337996Z","shell.execute_reply":"2024-06-04T13:19:10.736007Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m62/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0427 - loss: 0.5638","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1717507131.921624     119 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1717507131.937471     119 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0472 - loss: 0.5164","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717507134.486198     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1717507134.835459     119 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n - val_f1_score: 0.1263\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - accuracy: 0.0476 - loss: 0.5133 - val_accuracy: 0.2037 - val_loss: 0.1073\nEpoch 2/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1767 - loss: 0.137\n - val_f1_score: 0.2710\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1805 - loss: 0.1353 - val_accuracy: 0.3823 - val_loss: 0.0852\nEpoch 3/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2774 - loss: 0.107\n - val_f1_score: 0.2915\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2810 - loss: 0.1066 - val_accuracy: 0.4357 - val_loss: 0.0791\nEpoch 4/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3512 - loss: 0.090\n - val_f1_score: 0.4158\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3537 - loss: 0.0899 - val_accuracy: 0.4858 - val_loss: 0.0664\nEpoch 5/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4120 - loss: 0.079\n - val_f1_score: 0.4759\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4125 - loss: 0.0797 - val_accuracy: 0.4825 - val_loss: 0.0621\nEpoch 6/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4378 - loss: 0.076\n - val_f1_score: 0.4893\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4404 - loss: 0.0761 - val_accuracy: 0.5309 - val_loss: 0.0594\nEpoch 7/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4674 - loss: 0.069\n - val_f1_score: 0.5646\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4703 - loss: 0.0689 - val_accuracy: 0.5359 - val_loss: 0.0537\nEpoch 8/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4965 - loss: 0.065\n - val_f1_score: 0.6348\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: 0.0655 - val_accuracy: 0.5643 - val_loss: 0.0510\nEpoch 9/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5446 - loss: 0.058\n - val_f1_score: 0.6432\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5443 - loss: 0.0589 - val_accuracy: 0.5876 - val_loss: 0.0472\nEpoch 10/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5600 - loss: 0.057\n - val_f1_score: 0.6364\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5594 - loss: 0.0570 - val_accuracy: 0.5626 - val_loss: 0.0480\nEpoch 11/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5658 - loss: 0.054\n - val_f1_score: 0.6610\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5651 - loss: 0.0549 - val_accuracy: 0.5943 - val_loss: 0.0437\nEpoch 12/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5733 - loss: 0.052\n - val_f1_score: 0.6531\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5741 - loss: 0.0524 - val_accuracy: 0.5893 - val_loss: 0.0432\nEpoch 13/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5778 - loss: 0.051\n - val_f1_score: 0.7139\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5802 - loss: 0.0507 - val_accuracy: 0.6160 - val_loss: 0.0396\nEpoch 14/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6151 - loss: 0.048\n - val_f1_score: 0.7409\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6146 - loss: 0.0484 - val_accuracy: 0.6077 - val_loss: 0.0385\nEpoch 15/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6167 - loss: 0.045\n - val_f1_score: 0.7397\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6165 - loss: 0.0454 - val_accuracy: 0.6477 - val_loss: 0.0367\nEpoch 16/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6222 - loss: 0.044\n - val_f1_score: 0.6922\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6221 - loss: 0.0442 - val_accuracy: 0.6327 - val_loss: 0.0374\nEpoch 17/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6429 - loss: 0.042\n - val_f1_score: 0.7539\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6435 - loss: 0.0423 - val_accuracy: 0.6210 - val_loss: 0.0345\nEpoch 18/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6564 - loss: 0.040\n - val_f1_score: 0.7866\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6556 - loss: 0.0405 - val_accuracy: 0.6444 - val_loss: 0.0334\nEpoch 19/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6513 - loss: 0.037\n - val_f1_score: 0.7687\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6511 - loss: 0.0374 - val_accuracy: 0.6327 - val_loss: 0.0327\nEpoch 20/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6540 - loss: 0.039\n - val_f1_score: 0.7275\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6511 - loss: 0.0392 - val_accuracy: 0.6477 - val_loss: 0.0356\nEpoch 21/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6565 - loss: 0.037\n - val_f1_score: 0.7890\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6565 - loss: 0.0377 - val_accuracy: 0.6327 - val_loss: 0.0310\nEpoch 22/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6481 - loss: 0.038\n - val_f1_score: 0.7911\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6521 - loss: 0.0377 - val_accuracy: 0.6578 - val_loss: 0.0292\nEpoch 23/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6756 - loss: 0.034\n - val_f1_score: 0.7954\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.0350 - val_accuracy: 0.6528 - val_loss: 0.0294\nEpoch 24/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6631 - loss: 0.033\n - val_f1_score: 0.8261\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6642 - loss: 0.0337 - val_accuracy: 0.6711 - val_loss: 0.0270\nEpoch 25/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6845 - loss: 0.033\n - val_f1_score: 0.7818\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6842 - loss: 0.0333 - val_accuracy: 0.6711 - val_loss: 0.0291\nEpoch 26/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6912 - loss: 0.033\n - val_f1_score: 0.8265\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6910 - loss: 0.0331 - val_accuracy: 0.6678 - val_loss: 0.0258\nEpoch 27/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6943 - loss: 0.031\n - val_f1_score: 0.8140\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6919 - loss: 0.0317 - val_accuracy: 0.6661 - val_loss: 0.0255\nEpoch 28/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6989 - loss: 0.029\n - val_f1_score: 0.8560\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6976 - loss: 0.0300 - val_accuracy: 0.6895 - val_loss: 0.0242\nEpoch 29/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7233 - loss: 0.027\n - val_f1_score: 0.8523\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7203 - loss: 0.0279 - val_accuracy: 0.6578 - val_loss: 0.0237\nEpoch 30/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6868 - loss: 0.029\n - val_f1_score: 0.8347\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6899 - loss: 0.0295 - val_accuracy: 0.6962 - val_loss: 0.0241\nEpoch 31/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7076 - loss: 0.029\n - val_f1_score: 0.8806\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7075 - loss: 0.0292 - val_accuracy: 0.6678 - val_loss: 0.0206\nEpoch 32/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6953 - loss: 0.028\n - val_f1_score: 0.8508\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6968 - loss: 0.0283 - val_accuracy: 0.7062 - val_loss: 0.0219\nEpoch 33/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7137 - loss: 0.028\n - val_f1_score: 0.8460\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7124 - loss: 0.0283 - val_accuracy: 0.6795 - val_loss: 0.0232\nEpoch 34/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7010 - loss: 0.027\n - val_f1_score: 0.8579\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7023 - loss: 0.0271 - val_accuracy: 0.6945 - val_loss: 0.0218\nEpoch 35/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7193 - loss: 0.026\n - val_f1_score: 0.8870\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7180 - loss: 0.0261 - val_accuracy: 0.7078 - val_loss: 0.0210\nEpoch 36/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7067 - loss: 0.026\n - val_f1_score: 0.8740\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7071 - loss: 0.0269 - val_accuracy: 0.6895 - val_loss: 0.0205\nEpoch 37/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7157 - loss: 0.025\n - val_f1_score: 0.9021\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7154 - loss: 0.0253 - val_accuracy: 0.6978 - val_loss: 0.0178\nEpoch 38/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7375 - loss: 0.023\n - val_f1_score: 0.8729\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.0237 - val_accuracy: 0.6828 - val_loss: 0.0204\nEpoch 39/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7059 - loss: 0.024\n - val_f1_score: 0.8701\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7057 - loss: 0.0242 - val_accuracy: 0.7012 - val_loss: 0.0202\nEpoch 40/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7148 - loss: 0.025\n - val_f1_score: 0.9045\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7180 - loss: 0.0249 - val_accuracy: 0.7012 - val_loss: 0.0169\nEpoch 41/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7226 - loss: 0.022\n - val_f1_score: 0.9044\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7251 - loss: 0.0228 - val_accuracy: 0.6978 - val_loss: 0.0173\nEpoch 42/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7372 - loss: 0.023\n - val_f1_score: 0.8810\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.0235 - val_accuracy: 0.6928 - val_loss: 0.0179\nEpoch 43/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7402 - loss: 0.021\n - val_f1_score: 0.8852\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7402 - loss: 0.0218 - val_accuracy: 0.7062 - val_loss: 0.0174\nEpoch 44/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7326 - loss: 0.021\n - val_f1_score: 0.9136\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.0219 - val_accuracy: 0.6945 - val_loss: 0.0160\nEpoch 45/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7459 - loss: 0.022\n - val_f1_score: 0.8929\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7445 - loss: 0.0226 - val_accuracy: 0.7245 - val_loss: 0.0165\nEpoch 46/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7265 - loss: 0.021\n - val_f1_score: 0.8999\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.0217 - val_accuracy: 0.7028 - val_loss: 0.0163\nEpoch 47/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.021\n - val_f1_score: 0.8933\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7342 - loss: 0.0213 - val_accuracy: 0.6811 - val_loss: 0.0177\nEpoch 48/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7334 - loss: 0.022\n - val_f1_score: 0.9251\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7343 - loss: 0.0228 - val_accuracy: 0.7179 - val_loss: 0.0148\nEpoch 49/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.020\n - val_f1_score: 0.8825\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7384 - loss: 0.0204 - val_accuracy: 0.7145 - val_loss: 0.0176\nEpoch 50/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7253 - loss: 0.021\n - val_f1_score: 0.9060\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7275 - loss: 0.0212 - val_accuracy: 0.7062 - val_loss: 0.0154\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c45c529a290>"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\ny_pred = vgg2.predict(X_test)\nprint(classification_report(y_test, y_pred > 0.5, target_names=mlb.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:44.251433Z","iopub.execute_input":"2024-06-04T13:19:44.251829Z","iopub.status.idle":"2024-06-04T13:19:44.374129Z","shell.execute_reply.started":"2024-06-04T13:19:44.251795Z","shell.execute_reply":"2024-06-04T13:19:44.373036Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n                                precision    recall  f1-score   support\n\n                   Auto racing       1.00      1.00      1.00        21\n                      Business       1.00      0.46      0.63        50\n                         Games       1.00      0.50      0.67        14\n                   Health care       1.00      0.94      0.97        16\n             Physical exercise       0.92      0.94      0.93        35\n            alcoholic beverage       1.00      0.94      0.97        16\n             american football       1.00      1.00      1.00        10\n                 art and music       1.00      0.62      0.76        13\n                      baseball       1.00      1.00      1.00         5\n                    basketball       1.00      0.57      0.73        14\n                        beauty       1.00      1.00      1.00        40\n                     beverages       1.00      0.95      0.97        19\n                  bodybuilding       0.90      1.00      0.95        19\n                       camping       1.00      1.00      1.00        13\n                      clothing       0.92      0.84      0.88        57\n                     computers       1.00      0.69      0.82        13\n          consumer electronics       0.87      0.93      0.90        14\n           cooking and cuisine       1.00      0.78      0.88        18\ncurrent event homes and garden       1.00      1.00      1.00        16\n            dating and mariage       1.00      0.47      0.64        32\n                        family       1.00      0.77      0.87        39\n           fashion accessories       0.96      0.95      0.96        57\n                       fishing       1.00      1.00      1.00         7\n           food and restaurant       0.91      0.91      0.91        11\n               football/soccer       1.00      1.00      1.00        17\n                          golf       1.00      1.00      1.00        10\n                      handball       1.00      1.00      1.00         7\n                        hiking       1.00      1.00      1.00         7\n              horseback riding       1.00      1.00      1.00        12\n                   live events       1.00      0.65      0.79        17\n                      marathon       0.90      1.00      0.95         9\n                        movies       1.00      0.67      0.80        12\n                         music       1.00      0.88      0.94        25\n                     parenting       1.00      0.92      0.96        24\n                          pets       1.00      1.00      1.00        34\n  political and socials issues       0.86      0.75      0.80        16\n                       reading       1.00      0.91      0.95        11\n                       running       1.00      0.57      0.73         7\n                      shopping       1.00      0.92      0.96        25\n                        skiing       1.00      1.00      1.00         4\n                  social media       0.94      0.86      0.90        74\n                      swimming       1.00      1.00      1.00         7\n                        tennis       1.00      0.63      0.77        19\n                          toys       1.00      1.00      1.00        11\n                        travel       1.00      0.92      0.96        26\n                 tv and series       0.83      1.00      0.91        15\n                      vehicles       1.00      0.92      0.96        25\n                    volleyball       1.00      0.60      0.75        10\n                          yoga       1.00      0.88      0.93        16\n\n                     micro avg       0.97      0.85      0.91       989\n                     macro avg       0.98      0.86      0.91       989\n                  weighted avg       0.98      0.85      0.90       989\n                   samples avg       0.87      0.84      0.84       989\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg3 = Sequential([\n    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(49, activation='sigmoid')\n])\n\nvgg3.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:10.738442Z","iopub.execute_input":"2024-06-04T13:19:10.738759Z","iopub.status.idle":"2024-06-04T13:19:10.795572Z","shell.execute_reply.started":"2024-06-04T13:19:10.738732Z","shell.execute_reply":"2024-06-04T13:19:10.794578Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"vgg3.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,validation_data=(X_test, y_test), callbacks=[F1ScoreCallback()])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:19:10.796810Z","iopub.execute_input":"2024-06-04T13:19:10.797163Z","iopub.status.idle":"2024-06-04T13:19:44.249342Z","shell.execute_reply.started":"2024-06-04T13:19:10.797137Z","shell.execute_reply":"2024-06-04T13:19:44.248388Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m53/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0284 - loss: 0.9073","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717507157.167632     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.0264 - loss: 0.8045","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717507165.753301     118 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\nW0000 00:00:1717507166.176561     119 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 219ms/step","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717507166.444099     116 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 129ms/step - accuracy: 0.0263 - loss: 0.8007 - val_accuracy: 0.0100 - val_loss: 0.1644\nEpoch 2/50\n\u001b[1m54/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0178 - loss: 0.2394   ","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1717507166.661559     117 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0189 - loss: 0.2335 - val_accuracy: 0.0033 - val_loss: 0.1467\nEpoch 3/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0306 - loss: 0.186\n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0303 - loss: 0.1852 - val_accuracy: 0.0050 - val_loss: 0.1494\nEpoch 4/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0244 - loss: 0.1745  \n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0234 - loss: 0.1744 - val_accuracy: 0.0033 - val_loss: 0.1455\nEpoch 5/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0352 - loss: 0.170\n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0344 - loss: 0.1691 - val_accuracy: 0.0033 - val_loss: 0.1449\nEpoch 6/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0242 - loss: 0.1597  \n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0264 - loss: 0.1603 - val_accuracy: 0.0301 - val_loss: 0.1544\nEpoch 7/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0289 - loss: 0.1561  \n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0293 - loss: 0.1562 - val_accuracy: 0.0417 - val_loss: 0.1513\nEpoch 8/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0355 - loss: 0.154\n - val_f1_score: 0.0000\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0357 - loss: 0.1543 - val_accuracy: 0.0601 - val_loss: 0.1422\nEpoch 9/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0442 - loss: 0.149\n - val_f1_score: 0.0240\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0462 - loss: 0.1500 - val_accuracy: 0.0651 - val_loss: 0.1371\nEpoch 10/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0615 - loss: 0.147\n - val_f1_score: 0.0435\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0604 - loss: 0.1473 - val_accuracy: 0.0684 - val_loss: 0.1335\nEpoch 11/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0577 - loss: 0.144\n - val_f1_score: 0.0454\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0596 - loss: 0.1441 - val_accuracy: 0.0668 - val_loss: 0.1329\nEpoch 12/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0754 - loss: 0.141\n - val_f1_score: 0.0549\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0744 - loss: 0.1415 - val_accuracy: 0.0885 - val_loss: 0.1307\nEpoch 13/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0737 - loss: 0.1411\n - val_f1_score: 0.0644\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0747 - loss: 0.1411 - val_accuracy: 0.0935 - val_loss: 0.1285\nEpoch 14/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0786 - loss: 0.137\n - val_f1_score: 0.0681\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0798 - loss: 0.1383 - val_accuracy: 0.0918 - val_loss: 0.1283\nEpoch 15/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0804 - loss: 0.140\n - val_f1_score: 0.0813\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0800 - loss: 0.1403 - val_accuracy: 0.0985 - val_loss: 0.1257\nEpoch 16/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0978 - loss: 0.135\n - val_f1_score: 0.0683\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0963 - loss: 0.1358 - val_accuracy: 0.0952 - val_loss: 0.1252\nEpoch 17/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0817 - loss: 0.1331  \n - val_f1_score: 0.0775\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0863 - loss: 0.1332 - val_accuracy: 0.1119 - val_loss: 0.1237\nEpoch 18/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0934 - loss: 0.133\n - val_f1_score: 0.0794\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0933 - loss: 0.1332 - val_accuracy: 0.1202 - val_loss: 0.1208\nEpoch 19/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0922 - loss: 0.132\n - val_f1_score: 0.0757\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0907 - loss: 0.1323 - val_accuracy: 0.1352 - val_loss: 0.1186\nEpoch 20/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0933 - loss: 0.130\n - val_f1_score: 0.0997\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0944 - loss: 0.1304 - val_accuracy: 0.1553 - val_loss: 0.1156\nEpoch 21/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1119 - loss: 0.126\n - val_f1_score: 0.0795\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1108 - loss: 0.1266 - val_accuracy: 0.1669 - val_loss: 0.1128\nEpoch 22/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1151 - loss: 0.127\n - val_f1_score: 0.0831\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1148 - loss: 0.1278 - val_accuracy: 0.1686 - val_loss: 0.1126\nEpoch 23/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1019 - loss: 0.126\n - val_f1_score: 0.0958\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1022 - loss: 0.1260 - val_accuracy: 0.1753 - val_loss: 0.1091\nEpoch 24/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1423 - loss: 0.121\n - val_f1_score: 0.0977\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1409 - loss: 0.1215 - val_accuracy: 0.1736 - val_loss: 0.1080\nEpoch 25/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1209 - loss: 0.122\n - val_f1_score: 0.0831\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1214 - loss: 0.1225 - val_accuracy: 0.1669 - val_loss: 0.1085\nEpoch 26/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1189 - loss: 0.122\n - val_f1_score: 0.0831\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1204 - loss: 0.1222 - val_accuracy: 0.1836 - val_loss: 0.1075\nEpoch 27/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1321 - loss: 0.1168\n - val_f1_score: 0.0972\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1307 - loss: 0.1175 - val_accuracy: 0.1853 - val_loss: 0.1041\nEpoch 28/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1100 - loss: 0.1224  \n - val_f1_score: 0.0757\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1149 - loss: 0.1215 - val_accuracy: 0.1987 - val_loss: 0.1046\nEpoch 29/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1371 - loss: 0.119\n - val_f1_score: 0.1045\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1378 - loss: 0.1185 - val_accuracy: 0.1970 - val_loss: 0.1031\nEpoch 30/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1260 - loss: 0.117\n - val_f1_score: 0.1010\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1301 - loss: 0.1173 - val_accuracy: 0.2187 - val_loss: 0.1022\nEpoch 31/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1195 - loss: 0.117\n - val_f1_score: 0.0956\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1237 - loss: 0.1175 - val_accuracy: 0.2304 - val_loss: 0.1011\nEpoch 32/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1408 - loss: 0.113\n - val_f1_score: 0.0921\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1396 - loss: 0.1144 - val_accuracy: 0.1853 - val_loss: 0.1064\nEpoch 33/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1529 - loss: 0.113\n - val_f1_score: 0.0885\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1526 - loss: 0.1137 - val_accuracy: 0.2037 - val_loss: 0.0997\nEpoch 34/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1436 - loss: 0.113\n - val_f1_score: 0.0974\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1453 - loss: 0.1133 - val_accuracy: 0.2321 - val_loss: 0.0992\nEpoch 35/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1422 - loss: 0.114\n - val_f1_score: 0.0994\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1436 - loss: 0.1145 - val_accuracy: 0.2220 - val_loss: 0.0974\nEpoch 36/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1563 - loss: 0.113\n - val_f1_score: 0.1103\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1545 - loss: 0.1128 - val_accuracy: 0.2554 - val_loss: 0.0958\nEpoch 37/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1814 - loss: 0.107\n - val_f1_score: 0.1102\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1777 - loss: 0.1080 - val_accuracy: 0.2371 - val_loss: 0.0961\nEpoch 38/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1766 - loss: 0.106\n - val_f1_score: 0.1156\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1727 - loss: 0.1076 - val_accuracy: 0.2371 - val_loss: 0.0948\nEpoch 39/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1584 - loss: 0.108\n - val_f1_score: 0.1010\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1610 - loss: 0.1081 - val_accuracy: 0.2705 - val_loss: 0.0939\nEpoch 40/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1709 - loss: 0.107\n - val_f1_score: 0.1327\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1719 - loss: 0.1082 - val_accuracy: 0.2437 - val_loss: 0.0930\nEpoch 41/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1597 - loss: 0.108\n - val_f1_score: 0.1051\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1598 - loss: 0.1081 - val_accuracy: 0.2321 - val_loss: 0.0976\nEpoch 42/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1813 - loss: 0.109\n - val_f1_score: 0.1382\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1795 - loss: 0.1087 - val_accuracy: 0.2287 - val_loss: 0.0929\nEpoch 43/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1818 - loss: 0.108\n - val_f1_score: 0.1468\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1791 - loss: 0.1077 - val_accuracy: 0.2821 - val_loss: 0.0903\nEpoch 44/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1908 - loss: 0.103\n - val_f1_score: 0.1239\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1917 - loss: 0.1039 - val_accuracy: 0.2805 - val_loss: 0.0902\nEpoch 45/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2019 - loss: 0.101\n - val_f1_score: 0.1433\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1986 - loss: 0.1022 - val_accuracy: 0.2788 - val_loss: 0.0903\nEpoch 46/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1732 - loss: 0.105\n - val_f1_score: 0.1401\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1763 - loss: 0.1052 - val_accuracy: 0.2538 - val_loss: 0.0883\nEpoch 47/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1820 - loss: 0.102\n - val_f1_score: 0.1503\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1832 - loss: 0.1025 - val_accuracy: 0.2688 - val_loss: 0.0876\nEpoch 48/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1958 - loss: 0.100\n - val_f1_score: 0.1403\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1953 - loss: 0.1013 - val_accuracy: 0.2688 - val_loss: 0.0889\nEpoch 49/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1971 - loss: 0.104\n - val_f1_score: 0.1454\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1937 - loss: 0.1044 - val_accuracy: 0.2621 - val_loss: 0.0890\nEpoch 50/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2095 - loss: 0.103\n - val_f1_score: 0.1446\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2080 - loss: 0.1030 - val_accuracy: 0.2705 - val_loss: 0.0882\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c456858afb0>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = vgg3.predict(X_test)\nprint(classification_report(y_test, y_pred > 0.5, target_names=mlb.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:20:07.977759Z","iopub.execute_input":"2024-06-04T13:20:07.978161Z","iopub.status.idle":"2024-06-04T13:20:08.110093Z","shell.execute_reply.started":"2024-06-04T13:20:07.978129Z","shell.execute_reply":"2024-06-04T13:20:08.109030Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n                                precision    recall  f1-score   support\n\n                   Auto racing       0.00      0.00      0.00        21\n                      Business       0.00      0.00      0.00        50\n                         Games       0.00      0.00      0.00        14\n                   Health care       0.00      0.00      0.00        16\n             Physical exercise       0.00      0.00      0.00        35\n            alcoholic beverage       0.91      0.62      0.74        16\n             american football       0.00      0.00      0.00        10\n                 art and music       0.00      0.00      0.00        13\n                      baseball       0.00      0.00      0.00         5\n                    basketball       0.00      0.00      0.00        14\n                        beauty       0.00      0.00      0.00        40\n                     beverages       0.00      0.00      0.00        19\n                  bodybuilding       0.00      0.00      0.00        19\n                       camping       0.00      0.00      0.00        13\n                      clothing       0.00      0.00      0.00        57\n                     computers       0.00      0.00      0.00        13\n          consumer electronics       0.00      0.00      0.00        14\n           cooking and cuisine       0.00      0.00      0.00        18\ncurrent event homes and garden       1.00      0.69      0.81        16\n            dating and mariage       0.00      0.00      0.00        32\n                        family       0.00      0.00      0.00        39\n           fashion accessories       0.00      0.00      0.00        57\n                       fishing       0.00      0.00      0.00         7\n           food and restaurant       0.00      0.00      0.00        11\n               football/soccer       0.00      0.00      0.00        17\n                          golf       0.00      0.00      0.00        10\n                      handball       0.00      0.00      0.00         7\n                        hiking       0.00      0.00      0.00         7\n              horseback riding       0.00      0.00      0.00        12\n                   live events       0.00      0.00      0.00        17\n                      marathon       0.00      0.00      0.00         9\n                        movies       0.00      0.00      0.00        12\n                         music       0.00      0.00      0.00        25\n                     parenting       0.00      0.00      0.00        24\n                          pets       0.92      1.00      0.96        34\n  political and socials issues       0.00      0.00      0.00        16\n                       reading       0.00      0.00      0.00        11\n                       running       0.00      0.00      0.00         7\n                      shopping       0.00      0.00      0.00        25\n                        skiing       0.00      0.00      0.00         4\n                  social media       0.00      0.00      0.00        74\n                      swimming       0.00      0.00      0.00         7\n                        tennis       0.00      0.00      0.00        19\n                          toys       0.00      0.00      0.00        11\n                        travel       0.00      0.00      0.00        26\n                 tv and series       0.00      0.00      0.00        15\n                      vehicles       0.74      0.92      0.82        25\n                    volleyball       0.00      0.00      0.00        10\n                          yoga       0.00      0.00      0.00        16\n\n                     micro avg       0.87      0.08      0.14       989\n                     macro avg       0.07      0.07      0.07       989\n                  weighted avg       0.08      0.08      0.08       989\n                   samples avg       0.13      0.11      0.12       989\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the neural network model\nvgg1 = Sequential([\n    Dense(y.shape[1], activation='sigmoid') \n])\n\n# Compile the model\nvgg1.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:20:24.281669Z","iopub.execute_input":"2024-06-04T13:20:24.282585Z","iopub.status.idle":"2024-06-04T13:20:24.295183Z","shell.execute_reply.started":"2024-06-04T13:20:24.282551Z","shell.execute_reply":"2024-06-04T13:20:24.294136Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"vgg1.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2,validation_data=(X_test, y_test), callbacks=[F1ScoreCallback()])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:20:24.452164Z","iopub.execute_input":"2024-06-04T13:20:24.452945Z","iopub.status.idle":"2024-06-04T13:20:41.615697Z","shell.execute_reply.started":"2024-06-04T13:20:24.452908Z","shell.execute_reply":"2024-06-04T13:20:41.614603Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step   accuracy: 0.0426 - loss: 0.\n - val_f1_score: 0.2270\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.0431 - loss: 0.4442 - val_accuracy: 0.1586 - val_loss: 0.1403\nEpoch 2/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2404 - loss: 0.122\n - val_f1_score: 0.3518\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2419 - loss: 0.1217 - val_accuracy: 0.3289 - val_loss: 0.1011\nEpoch 3/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3714 - loss: 0.090\n - val_f1_score: 0.4347\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3718 - loss: 0.0903 - val_accuracy: 0.3890 - val_loss: 0.0860\nEpoch 4/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4489 - loss: 0.078\n - val_f1_score: 0.4418\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4508 - loss: 0.0784 - val_accuracy: 0.4357 - val_loss: 0.0802\nEpoch 5/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5129 - loss: 0.071\n - val_f1_score: 0.4728\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5174 - loss: 0.0705 - val_accuracy: 0.5209 - val_loss: 0.0728\nEpoch 6/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5651 - loss: 0.061\n - val_f1_score: 0.5592\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5651 - loss: 0.0613 - val_accuracy: 0.5359 - val_loss: 0.0656\nEpoch 7/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5856 - loss: 0.056\n - val_f1_score: 0.5633\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5859 - loss: 0.0562 - val_accuracy: 0.4975 - val_loss: 0.0620\nEpoch 8/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6219 - loss: 0.052\n - val_f1_score: 0.6144\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6221 - loss: 0.0522 - val_accuracy: 0.5876 - val_loss: 0.0568\nEpoch 9/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6591 - loss: 0.048\n - val_f1_score: 0.6308\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 0.0480 - val_accuracy: 0.5576 - val_loss: 0.0542\nEpoch 10/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6622 - loss: 0.045\n - val_f1_score: 0.6623\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6626 - loss: 0.0458 - val_accuracy: 0.5977 - val_loss: 0.0518\nEpoch 11/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6818 - loss: 0.042\n - val_f1_score: 0.6738\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6811 - loss: 0.0425 - val_accuracy: 0.6294 - val_loss: 0.0497\nEpoch 12/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6671 - loss: 0.042\n - val_f1_score: 0.6784\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6675 - loss: 0.0423 - val_accuracy: 0.6160 - val_loss: 0.0473\nEpoch 13/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6887 - loss: 0.039\n - val_f1_score: 0.6846\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6887 - loss: 0.0393 - val_accuracy: 0.6227 - val_loss: 0.0464\nEpoch 14/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6966 - loss: 0.0392\n - val_f1_score: 0.7107\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7018 - loss: 0.0385 - val_accuracy: 0.6578 - val_loss: 0.0431\nEpoch 15/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7213 - loss: 0.035\n - val_f1_score: 0.7325\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7211 - loss: 0.0354 - val_accuracy: 0.6144 - val_loss: 0.0425\nEpoch 16/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7420 - loss: 0.032\n - val_f1_score: 0.7166\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.0322 - val_accuracy: 0.6311 - val_loss: 0.0412\nEpoch 17/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7278 - loss: 0.032\n - val_f1_score: 0.7440\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.0324 - val_accuracy: 0.6477 - val_loss: 0.0388\nEpoch 18/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7195 - loss: 0.031\n - val_f1_score: 0.7725\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7198 - loss: 0.0314 - val_accuracy: 0.6344 - val_loss: 0.0382\nEpoch 19/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7383 - loss: 0.029\n - val_f1_score: 0.7642\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.0295 - val_accuracy: 0.6912 - val_loss: 0.0370\nEpoch 20/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7515 - loss: 0.028\n - val_f1_score: 0.7718\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.0281 - val_accuracy: 0.6294 - val_loss: 0.0365\nEpoch 21/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.028\n - val_f1_score: 0.7704\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.0287 - val_accuracy: 0.6644 - val_loss: 0.0344\nEpoch 22/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7478 - loss: 0.026\n - val_f1_score: 0.7731\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.0265 - val_accuracy: 0.6561 - val_loss: 0.0346\nEpoch 23/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.025\n - val_f1_score: 0.7929\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.0255 - val_accuracy: 0.6711 - val_loss: 0.0339\nEpoch 24/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7706 - loss: 0.024\n - val_f1_score: 0.8122\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7692 - loss: 0.0249 - val_accuracy: 0.6728 - val_loss: 0.0315\nEpoch 25/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7549 - loss: 0.024\n - val_f1_score: 0.8248\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.0242 - val_accuracy: 0.6811 - val_loss: 0.0321\nEpoch 26/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7464 - loss: 0.024\n - val_f1_score: 0.8144\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.0240 - val_accuracy: 0.6861 - val_loss: 0.0310\nEpoch 27/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7607 - loss: 0.022\n - val_f1_score: 0.8319\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7609 - loss: 0.0226 - val_accuracy: 0.6945 - val_loss: 0.0303\nEpoch 28/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7742 - loss: 0.022\n - val_f1_score: 0.8229\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.0220 - val_accuracy: 0.6745 - val_loss: 0.0291\nEpoch 29/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7759 - loss: 0.021\n - val_f1_score: 0.8323\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7757 - loss: 0.0212 - val_accuracy: 0.6861 - val_loss: 0.0279\nEpoch 30/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7734 - loss: 0.020\n - val_f1_score: 0.8602\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.0203 - val_accuracy: 0.6978 - val_loss: 0.0269\nEpoch 31/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7720 - loss: 0.019\n - val_f1_score: 0.8502\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7720 - loss: 0.0193 - val_accuracy: 0.6811 - val_loss: 0.0282\nEpoch 32/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7826 - loss: 0.019\n - val_f1_score: 0.8629\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.0192 - val_accuracy: 0.7195 - val_loss: 0.0253\nEpoch 33/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7814 - loss: 0.018\n - val_f1_score: 0.8786\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7814 - loss: 0.0188 - val_accuracy: 0.6995 - val_loss: 0.0248\nEpoch 34/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.017\n - val_f1_score: 0.8762\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7942 - loss: 0.0175 - val_accuracy: 0.7279 - val_loss: 0.0241\nEpoch 35/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7665 - loss: 0.017\n - val_f1_score: 0.8418\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7680 - loss: 0.0176 - val_accuracy: 0.7095 - val_loss: 0.0252\nEpoch 36/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7842 - loss: 0.017\n - val_f1_score: 0.8785\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7840 - loss: 0.0178 - val_accuracy: 0.7179 - val_loss: 0.0230\nEpoch 37/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7768 - loss: 0.016\n - val_f1_score: 0.8888\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.0166 - val_accuracy: 0.7045 - val_loss: 0.0232\nEpoch 38/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7824 - loss: 0.016\n - val_f1_score: 0.8802\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7825 - loss: 0.0163 - val_accuracy: 0.6895 - val_loss: 0.0237\nEpoch 39/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 0.015\n - val_f1_score: 0.8943\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.0158 - val_accuracy: 0.7179 - val_loss: 0.0218\nEpoch 40/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.015\n - val_f1_score: 0.8954\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.0157 - val_accuracy: 0.7312 - val_loss: 0.0219\nEpoch 41/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7767 - loss: 0.014\n - val_f1_score: 0.9037\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.0144 - val_accuracy: 0.7295 - val_loss: 0.0223\nEpoch 42/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7890 - loss: 0.015\n - val_f1_score: 0.8945\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.0150 - val_accuracy: 0.7279 - val_loss: 0.0209\nEpoch 43/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8072 - loss: 0.013\n - val_f1_score: 0.9141\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8065 - loss: 0.0138 - val_accuracy: 0.7062 - val_loss: 0.0202\nEpoch 44/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7866 - loss: 0.013\n - val_f1_score: 0.9114\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7868 - loss: 0.0134 - val_accuracy: 0.7362 - val_loss: 0.0196\nEpoch 45/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7848 - loss: 0.013\n - val_f1_score: 0.9062\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7853 - loss: 0.0134 - val_accuracy: 0.7279 - val_loss: 0.0202\nEpoch 46/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8102 - loss: 0.012\n - val_f1_score: 0.9188\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.0123 - val_accuracy: 0.7212 - val_loss: 0.0201\nEpoch 47/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7915 - loss: 0.012\n - val_f1_score: 0.9293\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7913 - loss: 0.0127 - val_accuracy: 0.7412 - val_loss: 0.0183\nEpoch 48/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7867 - loss: 0.012\n - val_f1_score: 0.9199\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.0126 - val_accuracy: 0.7346 - val_loss: 0.0183\nEpoch 49/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7848 - loss: 0.012\n - val_f1_score: 0.9267\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7850 - loss: 0.0127 - val_accuracy: 0.7179 - val_loss: 0.0184\nEpoch 50/50\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7772 - loss: 0.012\n - val_f1_score: 0.9298\n\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.0121 - val_accuracy: 0.7362 - val_loss: 0.0179\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7c452a38f850>"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\ny_pred = vgg1.predict(X_test)\nprint(classification_report(y_test, y_pred > 0.5, target_names=mlb.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:20:45.073137Z","iopub.execute_input":"2024-06-04T13:20:45.073522Z","iopub.status.idle":"2024-06-04T13:20:45.193719Z","shell.execute_reply.started":"2024-06-04T13:20:45.073491Z","shell.execute_reply":"2024-06-04T13:20:45.192715Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n                                precision    recall  f1-score   support\n\n                   Auto racing       1.00      1.00      1.00        21\n                      Business       0.81      0.70      0.75        50\n                         Games       1.00      0.57      0.73        14\n                   Health care       1.00      1.00      1.00        16\n             Physical exercise       0.92      0.94      0.93        35\n            alcoholic beverage       1.00      1.00      1.00        16\n             american football       1.00      1.00      1.00        10\n                 art and music       1.00      1.00      1.00        13\n                      baseball       1.00      1.00      1.00         5\n                    basketball       1.00      0.93      0.96        14\n                        beauty       1.00      1.00      1.00        40\n                     beverages       0.83      1.00      0.90        19\n                  bodybuilding       1.00      1.00      1.00        19\n                       camping       1.00      1.00      1.00        13\n                      clothing       0.86      0.96      0.91        57\n                     computers       1.00      1.00      1.00        13\n          consumer electronics       0.88      1.00      0.93        14\n           cooking and cuisine       1.00      1.00      1.00        18\ncurrent event homes and garden       1.00      1.00      1.00        16\n            dating and mariage       0.90      0.59      0.72        32\n                        family       0.94      0.85      0.89        39\n           fashion accessories       0.97      0.98      0.97        57\n                       fishing       1.00      1.00      1.00         7\n           food and restaurant       0.92      1.00      0.96        11\n               football/soccer       1.00      1.00      1.00        17\n                          golf       1.00      1.00      1.00        10\n                      handball       1.00      1.00      1.00         7\n                        hiking       1.00      1.00      1.00         7\n              horseback riding       1.00      1.00      1.00        12\n                   live events       1.00      0.94      0.97        17\n                      marathon       1.00      1.00      1.00         9\n                        movies       1.00      1.00      1.00        12\n                         music       1.00      1.00      1.00        25\n                     parenting       1.00      0.67      0.80        24\n                          pets       1.00      1.00      1.00        34\n  political and socials issues       0.88      0.94      0.91        16\n                       reading       1.00      0.91      0.95        11\n                       running       1.00      0.86      0.92         7\n                      shopping       1.00      0.88      0.94        25\n                        skiing       1.00      1.00      1.00         4\n                  social media       0.86      0.84      0.85        74\n                      swimming       1.00      1.00      1.00         7\n                        tennis       1.00      0.53      0.69        19\n                          toys       1.00      1.00      1.00        11\n                        travel       1.00      0.88      0.94        26\n                 tv and series       0.83      1.00      0.91        15\n                      vehicles       1.00      1.00      1.00        25\n                    volleyball       1.00      0.70      0.82        10\n                          yoga       1.00      1.00      1.00        16\n\n                     micro avg       0.95      0.91      0.93       989\n                     macro avg       0.97      0.93      0.95       989\n                  weighted avg       0.95      0.91      0.93       989\n                   samples avg       0.90      0.90      0.89       989\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}